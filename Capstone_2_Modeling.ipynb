{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9800e236",
   "metadata": {},
   "source": [
    "Step 4: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc6c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#ignore warning messages to ensure clean outputs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72e0e7d",
   "metadata": {},
   "source": [
    "Applying the Machine Learning models:\n",
    "This is a classification problem, in supervised learning. Here we have used the following classification models:\n",
    "   \n",
    "   - Random Forest\n",
    "   - XGBoost\n",
    "   - Logistic Regression\n",
    "  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7fbe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'C:\\Users\\User\\Car_Accidents_preprocessed.pkl')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c8ce2e",
   "metadata": {},
   "source": [
    "Here we split the data between Train and Test (note we do not need to standardize our data since we are using strictly categorical data in this scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb04773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.columns[10:])\n",
    "#print(df.columns[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6fd1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X= df.drop(columns= df.columns[:10])\n",
    "y = df['DEATH OCCURED']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c75e0",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "\n",
    "    Pros:\n",
    "        - Works well with categorical data (transformation is not needed)\n",
    "        - Works well with a high number of features since they are randomly chosen from\n",
    "        - We will be able to see the feature importance\n",
    "    Cons:\n",
    "        - Has \"black box\" effect where much of what goes on in the model cannot be controlled\n",
    "        \n",
    "Potential Hyperperameters to tune:\n",
    "    n_estimators\n",
    "    max_features\n",
    "    max_depth\n",
    "    min_samples_split\n",
    "    bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8102ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# we bootstrap, use entropy and use 50 n_estimators just as starting points for this model\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True,n_estimators=50,criterion='entropy', random_state =1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#Predict using the model:\n",
    "\n",
    "y_predict_rf = rf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6737d542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[537030    130]\n",
      " [   674      8]]\n",
      "0.9985051371964258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_rf)\n",
    "print(cnf_matrix)\n",
    "Accuracy_rf=rf.score(X_test,y_test)\n",
    "print(Accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_test= cross_val_score(rf,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(rf,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "print(cv_scores_test)\n",
    "cv_scores_rf_test= cv_scores_test.mean()\n",
    "cv_scores_rf_train= cv_scores_train.mean()\n",
    "cv_scores_std_rf= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_rf_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_rf_train))\n",
    "print ('Standard deviation in cv scores: ' +str(cv_scores_std_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10afb4f",
   "metadata": {},
   "source": [
    "XGBoost:\n",
    "\n",
    "    Pros:\n",
    "    - Handles missing values well\n",
    "    - handles large data sets well\n",
    "    - fast to interpret and good execution speed\n",
    "    Cons:\n",
    "    - overfitting is possible if hyperparameters are not tuned correctly \n",
    "    - many hyperparameters can complicate things\n",
    "    \n",
    "Potential hyperparameters to tune: n_estimators, max_depth, learning_rate, n_jobs, min_child_weight, eval metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7636890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[537160      0]\n",
      " [   682      0]]\n",
      "0.9987319696118935\n"
     ]
    }
   ],
   "source": [
    "xgbModel = XGBClassifier(n_estimators=2, objective= 'binary:logistic', eval_metric= 'error', random_state=1)\n",
    "xgbModel.fit(X_train, y_train)\n",
    "y_predict_xgb = xgbModel.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict_xgb)\n",
    "print(cnf_matrix)\n",
    "Accuracy_xgb=xgbModel.score(X_test,y_test)\n",
    "print(Accuracy_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2924a",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "\n",
    "    Pros:\n",
    "    -Easy to implement\n",
    "    -efficient in train time\n",
    "    Cons:\n",
    "    - Prone to overfitting with high dimensionality \n",
    "    - has difficulty capturing complex relationships\n",
    "    - Does not work well with many features\n",
    "Potential Hyperparameters to tune: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6eb33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logreg = LogisticRegression(penalty = 'l2', C = .1,random_state = 40)\n",
    "Logreg.fit(X_train,y_train)\n",
    "y_pred_lr = Logreg.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa11a9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[537160      0]\n",
      " [   682      0]]\n",
      "0.9987319696118935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix= confusion_matrix(y_test,y_pred_lr)\n",
    "print(cnf_matrix)\n",
    "Accuracy_lr=Logreg.score(X_test,y_test)\n",
    "\n",
    "print(Accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832730a8",
   "metadata": {},
   "source": [
    "Comparison of Training Models\n",
    "We applied 3 different ML models and will evaluate their performance in terms of ROC AUC score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb68e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "myLabels = ['Random Forest','XGBoost','Logistic Regression']\n",
    "Accuracy_score = [Accuracy_rf, Accuracy_xgb, Accuracy_lr]\n",
    "\n",
    "score_tab = pd.DataFrame(list(zip(myLabels, Accuracy_score)), \n",
    "               columns =['Algorithm', 'Model accuracy score']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc200de1",
   "metadata": {},
   "source": [
    "Applying RandomSearchCV for hyperparameter tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c5235a",
   "metadata": {},
   "source": [
    "Random Forest hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_features='auto',random_state=1, n_jobs=-1)\n",
    "\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2,8,16], \"n_estimators\": [10,50,100,500]}\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "rs = rs.fit(X_train, y_train)\n",
    "\n",
    "print(rs.best_estimator_) \n",
    "print(rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1cd345",
   "metadata": {},
   "source": [
    "Fiiting Random Forest with optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c326415",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = # the hyperparameters from the test\n",
    "rf.fit(X_train, y_train)\n",
    "y_predictions_rf = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_predictions)\n",
    "cv = cross_val_score(rf, X_test, y_test,scoring='roc_auc').mean()\n",
    "print(acc)\n",
    "print(cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba8d060",
   "metadata": {},
   "source": [
    "Parameter Tuning for XBgoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [3,4,5,6,7], 'learning_rate':[.01,.1,.5], 'early_stopping_rounds':[2,4,6,8]}\n",
    "xgbModel = XGBClassifier( objective= 'binary:logistic', eval_metric= 'error', random_state=1)\n",
    "rs2 = RandomizedSearchCV(estimator = xbgModel, scoring='accuracy', cv=3, n_jobs =-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67022a35",
   "metadata": {},
   "source": [
    "Fitting XGBoost Model with Optimal Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbg = # the hyperparameters from the test\n",
    "xgb.fit(X_train, y_train)\n",
    "y_predictions_xgb = xgb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_predictions)\n",
    "cv = cross_val_score(xgb, X_test, y_test,scoring='roc_auc').mean()\n",
    "print(acc)\n",
    "print(cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6092f1",
   "metadata": {},
   "source": [
    "Parameter Tuning For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080228dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "logreg = LogisticRegression(penalty = 'l2',random_state = 40)\n",
    "rs3 = RandomizedSearchCV(estimator= logreg,scoring= 'acccuracy', cv=3, n_jobs =-1 )\n",
    "\n",
    "rs3 = rs.fit(X_train, y_train)\n",
    "print(rs3.best_estimator_)\n",
    "print(rs3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d01228",
   "metadata": {},
   "source": [
    "Fitting Logistic Regression with Optimal Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = # the hyperparameters from the test\n",
    "logreg.fit(X_train, y_train)\n",
    "y_predictions_log = log.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_predictions)\n",
    "cv = cross_val_score(logreg, X_test, y_test,scoring='roc_auc').mean()\n",
    "print(acc)\n",
    "print(cv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee64c5",
   "metadata": {},
   "source": [
    "Ranking performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ce791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot roc-auc scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e16c39",
   "metadata": {},
   "source": [
    "Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X\n",
    "importances = list(rf.feature_importances_)\n",
    "imp=np.sort(importances)\n",
    "tab=pd.DataFrame(list(zip(X,imp)),columns =['Features', 'Importance scores']) \n",
    "print(tab)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "#indices = np.argsort(importances)\n",
    "index = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "_=plt.barh(index,imp, align='center',color='b')\n",
    "plt.xlabel('Relative Importance',fontsize=15)\n",
    "plt.ylabel('Features',fontsize=15)\n",
    "plt.yticks(index, features)\n",
    "plt.title('Feature Importances for Random Forest classifier model',fontsize=15)\n",
    "plt.savefig(\"28.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f868d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X\n",
    "importances = list(xgb.feature_importances_)\n",
    "imp=np.sort(importances)\n",
    "tab=pd.DataFrame(list(zip(X,imp)),columns =['Features', 'Importance scores']) \n",
    "print(tab)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "#indices = np.argsort(importances)\n",
    "index = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "_=plt.barh(index,imp, align='center',color='b')\n",
    "plt.xlabel('Relative Importance',fontsize=15)\n",
    "plt.ylabel('Features',fontsize=15)\n",
    "plt.yticks(index, features)\n",
    "plt.title('Feature Importances for XGBoost model',fontsize=15)\n",
    "plt.savefig(\"28.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3a1cd",
   "metadata": {},
   "source": [
    "Conclusion and Further Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef23fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
